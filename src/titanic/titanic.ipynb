{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from constants import PROJECT_ROOT\n",
    "\n",
    "CHAPTER_ROOT = PROJECT_ROOT / \"notebooks\" / \"chapter_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_csv(CHAPTER_ROOT / \"data\" / \"titanic_data\" / \"train.csv\")\n",
    "df_test = pl.read_csv(CHAPTER_ROOT / \"data\" / \"titanic_data\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(\"Survived\")\n",
    "y = df_train.get_column(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"Pclass\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(\"Pclass\", \"survival_mean\")\n",
    "    .sort(by=\"Pclass\", descending=False)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pclass = pclass_vs_survival_mean.get_column(\"Pclass\").to_list()\n",
    "survivability = pclass_vs_survival_mean.get_column(\"survival_mean\").to_list()\n",
    "bar_labels = [f\"Class: {i} | Survivability: {survivability[i-1]:.2f}%\" for i in pclass]\n",
    "bar_colors = [\"yellow\", \"orange\", \"red\"]\n",
    "\n",
    "ax.bar(pclass, survivability, label=bar_labels, color=bar_colors)\n",
    "\n",
    "ax.set_ylabel(\"Survival Mean\")\n",
    "ax.set_xlabel(\"Ticket Class\")\n",
    "ax.legend(title=\"Survival Mean across different Ticket Classes\")\n",
    "ax.set_xticks(pclass)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Map Pclass values: 3 -> 1, 2 -> 2, and 1 -> 3 so that they are consistent with the increase in survivability rates.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_vs_survival_mean = df_train.with_columns(\n",
    "    pl.col(\"Name\").str.split(by=\" \").list.get(1).str.strip_chars_end(\".,\").alias(\"prefix\")\n",
    ")\n",
    "prefix_vs_survival_mean.get_column(\"prefix\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"Sex\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(\"Sex\", \"survival_mean\")\n",
    "    .sort(by=\"survival_mean\", descending=True)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "genders = sex_vs_survival_mean.get_column(\"Sex\").to_list()\n",
    "survivability = sex_vs_survival_mean.get_column(\"survival_mean\").to_list()\n",
    "bar_labels = [\n",
    "    f\"{gender} | Survivability: {surv_rate:.2f}%\"\n",
    "    for gender, surv_rate in zip(genders, survivability)\n",
    "]\n",
    "bar_colors = [\"yellow\", \"red\"]\n",
    "\n",
    "ax.bar(genders, survivability, label=bar_labels, color=bar_colors)\n",
    "\n",
    "ax.set_ylabel(\"Survival Rate\")\n",
    "ax.set_xlabel(\"Gender\")\n",
    "ax.legend(title=\"Survival Rate across Genders\")\n",
    "ax.set_xticks(genders)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Encode gender in a binary column where female = 1 and male = 0 to maintain the meaningful difference in survival rates.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Women's survival rate: {df_train.filter(pl.col('Sex') == 'female').get_column('Survived').mean():.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Men's survival rate: {df_train.filter(pl.col('Sex') == 'male').get_column('Survived').mean():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Survivor's mean fare: {df_train.filter(pl.col('Survived') == 1).get_column('Fare').mean():.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Non-Survivor's mean fare: {df_train.filter(pl.col('Survived') == 0).get_column('Fare').mean():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class AttributeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        drop_id: bool = True,\n",
    "        transform_cabin: bool = True,\n",
    "        transform_family: bool = True,\n",
    "        extract_prefix: bool = True,\n",
    "        extract_ticket_class: bool = True,\n",
    "    ):\n",
    "        self.drop_id = drop_id\n",
    "        self.transform_cabin = transform_cabin\n",
    "        self.transform_family = transform_family\n",
    "        self.extract_prefix = extract_prefix\n",
    "        self.extract_ticket_class = extract_ticket_class\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.transform_cabin:\n",
    "            X[\"Cabin\"] = X[\"Cabin\"].apply(lambda x: x[0] if x else \"0\")\n",
    "        if self.transform_family:\n",
    "            X[\"FamilySize\"] = X[\"SibSp\"] + X[\"Parch\"] + 1\n",
    "            X.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)\n",
    "        if self.extract_prefix:\n",
    "            X[\"Prefix\"] = X[\"Name\"].apply(lambda x: x.split()[1].rstrip(\".\"))\n",
    "            X.drop(\"Name\", axis=1, inplace=True)\n",
    "        if self.extract_ticket_class:\n",
    "            X[\"Ticket\"] = X[\"Ticket\"].apply(lambda x: x[0])\n",
    "            X.drop(\"Ticket\", axis=1, inplace=True)\n",
    "        if self.drop_id:\n",
    "            X.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "        return np.c_[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Name\", \"PassengerId\", \"Ticket\"]\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"attribs_transformer\", AttributeTransformer()),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_features = [\"Age\", \"Fare\"]\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"standard_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_feature = [\"Embarked\"]\n",
    "\n",
    "embark_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"embarked\", embark_pipeline, embarked_feature),\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline, cat_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.to_pandas(), y.to_pandas(), test_size=0.2, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline = full_pipeline.fit(X_train)\n",
    "\n",
    "X_train_transformed = fitted_pipeline.transform(X_train)\n",
    "X_val_transformed = fitted_pipeline.transform(X_val)\n",
    "X_test_transformed = fitted_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [10, 13, 15, 20],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 15, 20, 30, 50],\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_grid_search.best_score_)\n",
    "print(rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "rf_scores = cross_val_score(rf_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(rf_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_preds = rf_clf.predict(X_test_transformed)\n",
    "rf_score_test = accuracy_score(rf_preds, y_test)\n",
    "print(f\"Random Forest score on test set: {rf_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"tol\": [0.001, 0.01, 0.1, 1],\n",
    "    \"C\": [0.1, 1, 10, 20, 30, 40, 50, 100],\n",
    "    \"solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [1000, 1500, 2000],\n",
    "}\n",
    "\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_grid_search.best_score_)\n",
    "print(lr_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = lr_grid_search.best_estimator_\n",
    "\n",
    "lr_scores = cross_val_score(lr_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(lr_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr_clf.predict(X_test_transformed)\n",
    "lr_score_test = accuracy_score(lr_preds, y_test)\n",
    "print(f\"Logistic Regression score on test set: {lr_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_param_grid = {\n",
    "    \"C\": [10, 20, 30],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"degree\": [1, 2],\n",
    "    \"gamma\": [0.001, 0.1, 1, 3, 5],\n",
    "    \"tol\": [0.1, 1, 3, 5],\n",
    "}\n",
    "\n",
    "svc_grid_search = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=svc_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_grid_search.best_score_)\n",
    "print(svc_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = svc_grid_search.best_estimator_\n",
    "\n",
    "svc_scores = cross_val_score(svc_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(svc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = svc_clf.predict(X_test_transformed)\n",
    "svc_score_test = accuracy_score(svc_preds, y_test)\n",
    "print(f\"SVC score on test set: {svc_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"random_forest\", rf_clf),\n",
    "        (\"logistic_regression\", lr_clf),\n",
    "        (\"svc\", svc_clf),\n",
    "    ],\n",
    "    voting=\"hard\",\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_scores = cross_val_score(vote_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(vote_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = vote_clf.predict(X_test_transformed)\n",
    "vote_score_test = accuracy_score(vote_preds, y_test)\n",
    "print(f\"SVC score on test set: {vote_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = fitted_pipeline.transform(df_test.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RESULTS_DIR = CHAPTER_ROOT / \"results\"\n",
    "\n",
    "if not os.path.isdir(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_ids = pl.DataFrame({\"PassengerId\": df_test.get_column(\"PassengerId\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = [i.item() for i in rf_clf.predict(X_submit)]\n",
    "\n",
    "rf_preds = pl.DataFrame({\"Survived\": rf_preds})\n",
    "\n",
    "rf_preds_df = pl.concat(\n",
    "    [passenger_ids, rf_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "rf_preds_df.write_csv(RESULTS_DIR / \"rf_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = [i.item() for i in lr_clf.predict(X_submit)]\n",
    "\n",
    "lr_preds = pl.DataFrame({\"Survived\": lr_preds})\n",
    "\n",
    "lr_preds_df = pl.concat(\n",
    "    [passenger_ids, lr_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "lr_preds_df.write_csv(RESULTS_DIR / \"lr_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = [i.item() for i in svc_clf.predict(X_submit)]\n",
    "\n",
    "svc_preds = pl.DataFrame({\"Survived\": svc_preds})\n",
    "\n",
    "svc_preds_df = pl.concat(\n",
    "    [passenger_ids, svc_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "svc_preds_df.write_csv(RESULTS_DIR / \"svc_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = [i.item() for i in vote_clf.predict(X_submit)]\n",
    "\n",
    "vote_preds = pl.DataFrame({\"Survived\": vote_preds})\n",
    "\n",
    "vote_preds_df = pl.concat(\n",
    "    [passenger_ids, vote_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "vote_preds_df.write_csv(RESULTS_DIR / \"vote_preds.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
