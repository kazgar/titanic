{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import xlabel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from src.titanic.constants import PROJECT_ROOT\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_csv(DATA_DIR / \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colormap(df: pl.DataFrame, column: str = \"survival_mean\", cmap: str = \"cividis\") -> list:\n",
    "    norm = mcolors.Normalize(vmin=df[column].min(), vmax=df[column].max())\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    return [cmap(norm(surv_rate)) for surv_rate in df[column].to_list()]\n",
    "\n",
    "\n",
    "def plot_barplot(\n",
    "    df: pl.DataFrame,\n",
    "    x: list,\n",
    "    y: list,\n",
    "    labels: list,\n",
    "    title: str,\n",
    "    xlabel: str,\n",
    "    different_labels: list | None = None,\n",
    "    fontsize: str = \"large\",\n",
    "    title_fontsize: str = \"xx-large\",\n",
    "    ylabel: str = \"Survival Mean\",\n",
    "    figsize: tuple[int, int] = (12, 6),\n",
    "    set_ylim: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    bars = ax.bar(x, y, label=labels, color=get_colormap(df, **kwargs))\n",
    "\n",
    "    if set_ylim:\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            f\"{different_labels[i]:.2f}\" if different_labels else f\"{y[i]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.legend(title=title, title_fontsize=title_fontsize, fontsize=fontsize)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"Pclass\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(\"Pclass\", \"survival_mean\")\n",
    "    .sort(by=\"Pclass\", descending=False)\n",
    ")\n",
    "\n",
    "pclass = pclass_vs_survival_mean[\"Pclass\"].to_list()\n",
    "survivability = pclass_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "pclass_bar_labels = pclass\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=pclass_vs_survival_mean,\n",
    "    x=pclass,\n",
    "    y=survivability,\n",
    "    labels=pclass_bar_labels,\n",
    "    title=\"Survival Rate across different Ticket Classes\",\n",
    "    xlabel=\"Ticket Class\",\n",
    "    fontsize=\"xx-large\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(pclass)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_prevalence = df_train.get_column(\"Pclass\").value_counts().sort(by=\"Pclass\", descending=False)\n",
    "\n",
    "colors = get_colormap(pclass_prevalence, column=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(\n",
    "    pclass_prevalence[\"Pclass\"].cast(pl.String),\n",
    "    pclass_prevalence[\"count\"],\n",
    "    label=pclass_bar_labels,\n",
    "    color=colors,\n",
    ")\n",
    "ax.set_xlabel(\"Pclass\")\n",
    "ax.set_ylabel(\"Prevalence\")\n",
    "ax.legend(title=\"Pclass Distribution\", title_fontsize=\"xx-large\", fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Map Pclass values: 3 -> 1, 2 -> 2, and 1 -> 3 so that they are consistent with the increase in survivability rates.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "prefix_vs_survival_mean = (\n",
    "    df_train.with_columns(\n",
    "        pl.col(\"Name\").str.split(by=\".\").list.get(0).str.split(by=\" \").list.get(-1).alias(\"prefix\")\n",
    "    )\n",
    "    .group_by(pl.col(\"prefix\"))\n",
    "    .all()\n",
    "    .with_columns(\n",
    "        pl.col(\"prefix\"),\n",
    "        pl.col(\"Survived\").list.mean().alias(\"survival_mean\"),\n",
    "    )\n",
    "    .select(\"prefix\", \"survival_mean\")\n",
    "    .sort(by=\"survival_mean\", descending=False)\n",
    ")\n",
    "\n",
    "prefix_prevalence = (\n",
    "    df_train.with_columns(\n",
    "        pl.col(\"Name\").str.split(by=\".\").list.get(0).str.split(by=\" \").list.get(-1).alias(\"prefix\")\n",
    "    ).select(pl.col(\"prefix\").value_counts())\n",
    ").unnest(\"prefix\")\n",
    "\n",
    "prefixes = prefix_vs_survival_mean[\"prefix\"].to_list()\n",
    "survivability = prefix_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "prevalence = [\n",
    "    prefix_prevalence.filter(pl.col(\"prefix\") == prefix).get_column(\"count\").first()\n",
    "    for prefix in prefixes\n",
    "]\n",
    "prefix_bar_labels = [prefix for prefix, surv_rate in zip(prefixes, survivability)]\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=prefix_vs_survival_mean,\n",
    "    x=prefixes,\n",
    "    y=prevalence,\n",
    "    labels=prefix_bar_labels,\n",
    "    different_labels=survivability,\n",
    "    title=\"Survival Rate across different Prefixes\",\n",
    "    ylabel=\"Prevalence\",\n",
    "    xlabel=\"Prefix\",\n",
    "    title_fontsize=\"x-large\",\n",
    "    fontsize=\"medium\",\n",
    "    figsize=(15, 6),\n",
    "    set_ylim=False,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Group rare prefixes (prevalence < 3) and then use one hot encoding to encode them with the rest of them.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"Sex\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(\"Sex\", \"survival_mean\")\n",
    "    .sort(by=\"survival_mean\", descending=True)\n",
    ")\n",
    "\n",
    "genders = sex_vs_survival_mean[\"Sex\"].to_list()\n",
    "survivability = sex_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "sex_bar_labels = genders\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=sex_vs_survival_mean,\n",
    "    x=genders,\n",
    "    y=survivability,\n",
    "    labels=sex_bar_labels,\n",
    "    title=\"Survival Rate across different Genders\",\n",
    "    xlabel=\"Gender\",\n",
    "    fontsize=\"xx-large\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_prevalence = df_train.get_column(\"Sex\").value_counts().sort(by=\"Sex\")\n",
    "\n",
    "colors = get_colormap(sex_prevalence, column=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(sex_prevalence[\"Sex\"], sex_prevalence[\"count\"], label=sex_bar_labels, color=colors)\n",
    "ax.set_xlabel(\"Sex\")\n",
    "ax.set_ylabel(\"Prevalence\")\n",
    "ax.legend(title=\"Sex Distribution\", title_fontsize=\"xx-large\", fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Encode gender in a binary column where female = 1 and male = 0 to maintain the meaningful difference in survival rates.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump = 10\n",
    "age_grouping = {f\"{i*jump}-{i*jump+jump}\": i for i in range(int(df_train[\"Age\"].max() + 1) // jump)}\n",
    "\n",
    "\n",
    "def map_age(age):\n",
    "    for grp in age_grouping.keys():\n",
    "        upper = float(grp.split(\"-\")[-1])\n",
    "        if float(age) <= upper:\n",
    "            return age_grouping[grp]\n",
    "\n",
    "\n",
    "age_group_vs_survival_mean = (\n",
    "    df_train.with_columns(\n",
    "        pl.col(\"Age\").map_elements(map_age, return_dtype=pl.Int8).alias(\"age_group\")\n",
    "    )\n",
    "    .group_by(pl.col(\"age_group\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(pl.col(\"age_group\"), pl.col(\"survival_mean\"))\n",
    "    .sort(by=\"age_group\", descending=False)\n",
    ")\n",
    "\n",
    "age_groups = age_group_vs_survival_mean[\"age_group\"].to_list()\n",
    "age_groups[0] = -1\n",
    "survivability = age_group_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "age_bar_labels = [\"Unknown\"] + [grp for grp in age_grouping.keys()]\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=age_group_vs_survival_mean,\n",
    "    x=age_groups,\n",
    "    y=survivability,\n",
    "    labels=age_bar_labels,\n",
    "    title=\"Survival Rate across different Age Groups\",\n",
    "    xlabel=\"Age Group\",\n",
    "    fontsize=\"medium\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(age_groups)\n",
    "ax.set_xticklabels(age_bar_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_prevalence = (\n",
    "    df_train.with_columns(\n",
    "        pl.col(\"Age\").map_elements(map_age, return_dtype=pl.Int8).alias(\"age_group\")\n",
    "    )\n",
    "    .get_column(\"age_group\")\n",
    "    .value_counts()\n",
    "    .sort(by=\"age_group\", descending=False)\n",
    ")\n",
    "\n",
    "colors = get_colormap(age_group_prevalence, column=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(\n",
    "    age_group_prevalence[\"age_group\"],\n",
    "    age_group_prevalence[\"count\"],\n",
    "    label=age_bar_labels,\n",
    "    color=colors,\n",
    ")\n",
    "ax.set_xlabel(\"Age Group\")\n",
    "ax.set_ylabel(\"Prevalence\")\n",
    "ax.set_xticks([age_group + 1 for age_group in age_groups])\n",
    "ax.set_xticklabels(age_bar_labels)\n",
    "ax.legend(title=\"Age Distribution\", title_fontsize=\"xx-large\", fontsize=\"x-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split into age categories (every 10 years), fill the nulls with median value for age.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sibsp_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"SibSp\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(pl.col(\"SibSp\"), pl.col(\"survival_mean\"))\n",
    "    .sort(by=\"SibSp\", descending=False)\n",
    ")\n",
    "\n",
    "sibsp_sizes = sibsp_vs_survival_mean[\"SibSp\"].to_list()\n",
    "survivability = sibsp_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "sibsp_bar_labels = sibsp_sizes\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=sibsp_vs_survival_mean,\n",
    "    x=sibsp_sizes,\n",
    "    y=survivability,\n",
    "    labels=sibsp_bar_labels,\n",
    "    title=\"Survival Rate across different SibSp values\",\n",
    "    xlabel=\"SibSp\",\n",
    "    fontsize=\"x-large\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(sibsp_sizes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sibsp_prevalence = df_train.get_column(\"SibSp\").value_counts().sort(by=\"SibSp\", descending=False)\n",
    "\n",
    "colors = get_colormap(sibsp_prevalence, column=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(\n",
    "    sibsp_prevalence[\"SibSp\"].cast(pl.String),\n",
    "    sibsp_prevalence[\"count\"],\n",
    "    label=sibsp_bar_labels,\n",
    "    color=colors,\n",
    ")\n",
    "ax.set_xlabel(\"SibSp\")\n",
    "ax.set_ylabel(\"Prevalence\")\n",
    "ax.legend(title=\"Pclass Distribution\", title_fontsize=\"xx-large\", fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_vs_survival_mean = (\n",
    "    df_train.group_by(pl.col(\"Parch\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(pl.col(\"Parch\"), pl.col(\"survival_mean\"))\n",
    "    .sort(by=\"Parch\", descending=False)\n",
    ")\n",
    "\n",
    "parch_sizes = parch_vs_survival_mean[\"Parch\"].to_list()\n",
    "survivability = parch_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "parch_bar_labels = parch_sizes\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=parch_vs_survival_mean,\n",
    "    x=parch_sizes,\n",
    "    y=survivability,\n",
    "    labels=parch_bar_labels,\n",
    "    title=\"Survival Rate across different Parch values\",\n",
    "    xlabel=\"Parch\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(parch_sizes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "parch_prevalence = df_train.get_column(\"Parch\").value_counts().sort(by=\"Parch\", descending=False)\n",
    "\n",
    "ax = parch_prevalence.to_pandas().plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"Parch\",\n",
    "    y=\"count\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Parch Distribution\",\n",
    "    legend=False,\n",
    "    rot=0,\n",
    "    colormap=\"cividis\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_vs_survival_mean = (\n",
    "    df_train.with_columns((pl.col(\"SibSp\") + pl.col(\"Parch\")).alias(\"family_size\"))\n",
    "    .group_by(pl.col(\"family_size\"))\n",
    "    .all()\n",
    "    .with_columns(pl.col(\"Survived\").list.mean().alias(\"survival_mean\"))\n",
    "    .select(pl.col(\"family_size\"), pl.col(\"survival_mean\"))\n",
    "    .sort(by=\"family_size\", descending=False)\n",
    ")\n",
    "\n",
    "family_sizes = family_size_vs_survival_mean[\"family_size\"].to_list()\n",
    "survivability = family_size_vs_survival_mean[\"survival_mean\"].to_list()\n",
    "bar_labels = family_sizes\n",
    "\n",
    "ax = plot_barplot(\n",
    "    df=family_size_vs_survival_mean,\n",
    "    x=family_sizes,\n",
    "    y=survivability,\n",
    "    labels=bar_labels,\n",
    "    title=\"Survival Rate across different Family Sizes\",\n",
    "    xlabel=\"Family Size\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(family_sizes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_prevalence = (\n",
    "    df_train.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class AttributeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        drop_id: bool = True,\n",
    "        transform_cabin: bool = True,\n",
    "        transform_family: bool = True,\n",
    "        extract_prefix: bool = True,\n",
    "        extract_ticket_class: bool = True,\n",
    "    ):\n",
    "        self.drop_id = drop_id\n",
    "        self.transform_cabin = transform_cabin\n",
    "        self.transform_family = transform_family\n",
    "        self.extract_prefix = extract_prefix\n",
    "        self.extract_ticket_class = extract_ticket_class\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.transform_cabin:\n",
    "            X[\"Cabin\"] = X[\"Cabin\"].apply(lambda x: x[0] if x else \"0\")\n",
    "        if self.transform_family:\n",
    "            X[\"FamilySize\"] = X[\"SibSp\"] + X[\"Parch\"] + 1\n",
    "            X.drop([\"SibSp\", \"Parch\"], axis=1, inplace=True)\n",
    "        if self.extract_prefix:\n",
    "            X[\"Prefix\"] = X[\"Name\"].apply(lambda x: x.split()[1].rstrip(\".\"))\n",
    "            X.drop(\"Name\", axis=1, inplace=True)\n",
    "        if self.extract_ticket_class:\n",
    "            X[\"Ticket\"] = X[\"Ticket\"].apply(lambda x: x[0])\n",
    "            X.drop(\"Ticket\", axis=1, inplace=True)\n",
    "        if self.drop_id:\n",
    "            X.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "        return np.c_[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Name\", \"PassengerId\", \"Ticket\"]\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"attribs_transformer\", AttributeTransformer()),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_features = [\"Age\", \"Fare\"]\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"standard_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_feature = [\"Embarked\"]\n",
    "\n",
    "embark_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one_hot_encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"embarked\", embark_pipeline, embarked_feature),\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cat\", cat_pipeline, cat_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.to_pandas(), y.to_pandas(), test_size=0.2, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline = full_pipeline.fit(X_train)\n",
    "\n",
    "X_train_transformed = fitted_pipeline.transform(X_train)\n",
    "X_val_transformed = fitted_pipeline.transform(X_val)\n",
    "X_test_transformed = fitted_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [10, 13, 15, 20],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 15, 20, 30, 50],\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_grid_search.best_score_)\n",
    "print(rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "rf_scores = cross_val_score(rf_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(rf_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_preds = rf_clf.predict(X_test_transformed)\n",
    "rf_score_test = accuracy_score(rf_preds, y_test)\n",
    "print(f\"Random Forest score on test set: {rf_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"tol\": [0.001, 0.01, 0.1, 1],\n",
    "    \"C\": [0.1, 1, 10, 20, 30, 40, 50, 100],\n",
    "    \"solver\": [\"liblinear\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [1000, 1500, 2000],\n",
    "}\n",
    "\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_grid_search.best_score_)\n",
    "print(lr_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = lr_grid_search.best_estimator_\n",
    "\n",
    "lr_scores = cross_val_score(lr_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(lr_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr_clf.predict(X_test_transformed)\n",
    "lr_score_test = accuracy_score(lr_preds, y_test)\n",
    "print(f\"Logistic Regression score on test set: {lr_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_param_grid = {\n",
    "    \"C\": [10, 20, 30],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"degree\": [1, 2],\n",
    "    \"gamma\": [0.001, 0.1, 1, 3, 5],\n",
    "    \"tol\": [0.1, 1, 3, 5],\n",
    "}\n",
    "\n",
    "svc_grid_search = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid=svc_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=1,\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svc_grid_search.best_score_)\n",
    "print(svc_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = svc_grid_search.best_estimator_\n",
    "\n",
    "svc_scores = cross_val_score(svc_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(svc_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = svc_clf.predict(X_test_transformed)\n",
    "svc_score_test = accuracy_score(svc_preds, y_test)\n",
    "print(f\"SVC score on test set: {svc_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"random_forest\", rf_clf),\n",
    "        (\"logistic_regression\", lr_clf),\n",
    "        (\"svc\", svc_clf),\n",
    "    ],\n",
    "    voting=\"hard\",\n",
    ").fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_scores = cross_val_score(vote_clf, X_val_transformed, y_val, cv=10, scoring=\"accuracy\")\n",
    "\n",
    "print(vote_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = vote_clf.predict(X_test_transformed)\n",
    "vote_score_test = accuracy_score(vote_preds, y_test)\n",
    "print(f\"SVC score on test set: {vote_score_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = fitted_pipeline.transform(df_test.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RESULTS_DIR = CHAPTER_ROOT / \"results\"\n",
    "\n",
    "if not os.path.isdir(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_ids = pl.DataFrame({\"PassengerId\": df_test.get_column(\"PassengerId\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = [i.item() for i in rf_clf.predict(X_submit)]\n",
    "\n",
    "rf_preds = pl.DataFrame({\"Survived\": rf_preds})\n",
    "\n",
    "rf_preds_df = pl.concat(\n",
    "    [passenger_ids, rf_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "rf_preds_df.write_csv(RESULTS_DIR / \"rf_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = [i.item() for i in lr_clf.predict(X_submit)]\n",
    "\n",
    "lr_preds = pl.DataFrame({\"Survived\": lr_preds})\n",
    "\n",
    "lr_preds_df = pl.concat(\n",
    "    [passenger_ids, lr_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "lr_preds_df.write_csv(RESULTS_DIR / \"lr_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_preds = [i.item() for i in svc_clf.predict(X_submit)]\n",
    "\n",
    "svc_preds = pl.DataFrame({\"Survived\": svc_preds})\n",
    "\n",
    "svc_preds_df = pl.concat(\n",
    "    [passenger_ids, svc_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "svc_preds_df.write_csv(RESULTS_DIR / \"svc_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_preds = [i.item() for i in vote_clf.predict(X_submit)]\n",
    "\n",
    "vote_preds = pl.DataFrame({\"Survived\": vote_preds})\n",
    "\n",
    "vote_preds_df = pl.concat(\n",
    "    [passenger_ids, vote_preds],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "vote_preds_df.write_csv(RESULTS_DIR / \"vote_preds.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
